{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get JOURNAL NAME FROM PMID\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import lxml\n",
    "\n",
    "\n",
    "######################CHANGE DIRECTORY BASED ON WHERE UR FILES ARE.########################\n",
    "location = os.listdir(r'Directory of files you want to read')\n",
    "######################CHANGE DIRECTORY BASED ON WHERE UR FILES ARE.########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "length = len(location)\n",
    "pmids = np.array([])\n",
    "\n",
    "\n",
    "#Looks up PMID at Pubmed at finds associated Journal Name\n",
    "def journals(x):\n",
    "    journal_name = np.array([])\n",
    "    pmids = np.array([])\n",
    "    url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=pubmed&id='\n",
    "    api_key = '&examplePubmedApiKey'\n",
    "    for i in range(x, length):\n",
    "######################################################CHANGE 'FILES' BASED ON WHERE Your FILES ARE LOCATED.#################\n",
    "        files = os.listdir(r'Directory of files you want to read\\\\')[x]\n",
    "######################################################CHANGE 'FILES' BASED ON WHERE Your FILES ARE LOCATED.#################\n",
    "        \n",
    "        print('The file I am reading is: ' + files)\n",
    "    \n",
    "###############################CHANGE TEXt TO THE LOCATION THAT You WANT TO READ FILES FROM######################    \n",
    "        csv = pd.read_excel(io=r'Directory of files you want to read\\\\' + files, sheet_name='Sheet1')\n",
    "###############################CHANGE TExt TO THE LOCATION THAT You WANT TO READ FILES FROM######################  \n",
    "        \n",
    "        csv = csv.dropna(subset=['pmid'])\n",
    "    \n",
    "#i = author name\n",
    "#x = pmid    \n",
    "        for journal,pmid in csv.get(['journal', 'pmid']).itertuples(index=False):\n",
    "            name_to_string = str(journal)\n",
    "            string_to_int = int(pmid)\n",
    "            if name_to_string == 'nan':\n",
    "            #search for author name using pmid\n",
    "                try:\n",
    "                    rand_num = np.random.uniform(0.2, .4)\n",
    "                    time.sleep(rand_num) #random delay between 0.2 - 0.4 seconds so we dont hit api call limit\n",
    "                    page = requests.get(url + str(pmid) + api_key)\n",
    "                    print(page.status_code)\n",
    "                    print('The file I am reading is: ' + files)\n",
    "                    soup = bs(page.text, \"lxml-xml\")\n",
    "                    getting_closer = soup.find(\"Item\", {\"Name\":\"FullJournalName\"}).get_text(strip=True)\n",
    "                    journal_name = np.append(journal_name, getting_closer)\n",
    "                    if len(journal_name) >= len(csv.get('pmid')): #if length of journal array is equal or larger than the number of PMIDs in starting csv it will create export sheet\n",
    "                        author_df = pd.DataFrame().assign(Journal= journal_name)\n",
    "######################################EXPORT LOCATION OF FINISHED SHEETS in CSV FORM#####################################\n",
    "                        author_df.to_csv(r'Directory you want to save finished files on\\\\' + files + 'JOURNALS.csv')\n",
    "                        csv['Journals'] = journal_name\n",
    "################################################EXPORT LOCATION OF FINISHED SHEETS IN XLSX FORMAT#########################\n",
    "                        csv.to_excel(r'Directory you want to save finished files on\\\\' + files, index=False)\n",
    "                        x = x + 1\n",
    "                        #journals(x) uncomment here to iterate through the folder with multiple files\n",
    "                \n",
    "                except: #if it cant find a journal name it will append NA to the array\n",
    "                    journal_name = np.append(journal_name, \"NA\")\n",
    "                    \n",
    "            else: #if csv does not have empty journal column it will append data from journal column saving api calls\n",
    "            #add original author name\n",
    "                journal_name = np.append(journal_name, journal)\n",
    "                #print(len(authors))\n",
    "                if len(journal_name) >= len(csv.get('pmid')):  #if length of journal array is equal or larger than the number of PMIDs in starting csv it will create export sheet\n",
    "                    author_df = pd.DataFrame().assign(Journal= journal_name)\n",
    "######################################EXPORT LOCATION OF FINISHED SHEETS in CSV FORM#####################################\n",
    "                    author_df.to_csv(r'Directory you want to save finished files on\\\\' + files + 'JOURNALS.csv')\n",
    "                    csv['Journals'] = journal_name\n",
    "                    csv.to_excel(r'Directory you want to save finished files on\\\\' + files, index=False)\n",
    "                    x = x + 1\n",
    "                    #journals(x) uncomment here to iterate through the folder with multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals(0) #change the number based on which file you want to start with. 0 starts with first file in the directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
